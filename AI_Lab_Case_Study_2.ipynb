{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaouni24/Character-Recognition-and-Subjectivity-Detection/blob/main/AI_Lab_Case_Study_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Task 1: Character Recognission"
      ],
      "metadata": {
        "id": "m6rvA7D1Ouf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsMRj2Ka9JEB",
        "outputId": "45efd3ac-e1c0-4c43-b577-e461ef917cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "TDRcKCwwO1yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Dataset Preparation\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, mapping_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.mapping = {int(line.split()[0]): chr(int(line.split()[1])) for line in open(mapping_file).readlines()}\n",
        "        self.labels = self.data.iloc[:, 0].values  # First column is the label\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28)  # 28x28 images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx].astype(np.uint8)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(Image.fromarray(image))\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the datasets\n",
        "train_dataset = CharacterDataset('/content/characters.csv', '/content/mapping.txt', transform=transform)\n",
        "test_dataset = CharacterDataset('/content/characters-test.csv', '/content/mapping.txt', transform=transform)\n",
        "\n",
        "# Hyperparameters to loop over\n",
        "learning_rates = [0.01, 0.001, 0.003]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "# CNN Model Definition with configurable kernel sizes\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes, kernel_size1=5, kernel_size2=3):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # Convolution layers with configurable kernel sizes\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=kernel_size1, stride=1, padding=kernel_size1//2),  # Kernel size 5x5 or other\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=kernel_size2, stride=1, padding=kernel_size2//2),  # Kernel size 3x3 or other\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128),  # Flattened to match the number of features after convolution\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Loop over hyperparameters and train the model\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for kernel_size1 in [5, 3]:  # Testing different kernel sizes for the first convolutional layer\n",
        "            for kernel_size2 in [3, 5]:  # Testing different kernel sizes for the second convolutional layer\n",
        "                print(f\"Training with Learning Rate: {lr}, Batch Size: {batch_size}, Kernel Size1: {kernel_size1}, Kernel Size2: {kernel_size2}\")\n",
        "\n",
        "                # DataLoader for current batch size\n",
        "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                # Initialize model, loss function, and optimizer for this combination\n",
        "                model = CNNModel(num_classes=len(train_dataset.mapping), kernel_size1=kernel_size1, kernel_size2=kernel_size2)\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                # Training loop\n",
        "                for epoch in range(10):\n",
        "                    model.train()\n",
        "                    running_loss = 0.0\n",
        "                    for images, labels in train_loader:\n",
        "                        images, labels = images.float(), labels  # Ensure float type for images\n",
        "                        optimizer.zero_grad()\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        running_loss += loss.item()\n",
        "                    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "                # Testing and evaluation\n",
        "                model.eval()\n",
        "                y_true = []\n",
        "                y_pred = []\n",
        "                with torch.no_grad():\n",
        "                    for images, labels in test_loader:\n",
        "                        images, labels = images.float(), labels  # Ensure float type for images\n",
        "                        outputs = model(images)\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        y_true.extend(labels.numpy())\n",
        "                        y_pred.extend(predicted.numpy())\n",
        "\n",
        "                # Performance Metrics\n",
        "                accuracy = accuracy_score(y_true, y_pred)\n",
        "                precision = precision_score(y_true, y_pred, average='macro')\n",
        "                recall = recall_score(y_true, y_pred, average='macro')\n",
        "                f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "                print(f\"Results for LR: {lr}, Batch Size: {batch_size}, Kernel Size1: {kernel_size1}, Kernel Size2: {kernel_size2}\")\n",
        "                print(f\"Accuracy: {accuracy:.4f}\")\n",
        "                print(f\"Precision: {precision:.4f}\")\n",
        "                print(f\"Recall: {recall:.4f}\")\n",
        "                print(f\"F1 Score: {f1:.4f}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "                # Save the model for each configuration\n",
        "                torch.save(model.state_dict(), f\"trained_cnn_model_lr{lr}_bs{batch_size}_ks1{kernel_size1}_ks2{kernel_size2}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTa2NV29OA2",
        "outputId": "b856fd7c-4270-46eb-8613-062710e26d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Learning Rate: 0.01, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8279\n",
            "Epoch 2, Loss: 1.6621\n",
            "Epoch 3, Loss: 1.2974\n",
            "Epoch 4, Loss: 1.1463\n",
            "Epoch 5, Loss: 1.0494\n",
            "Epoch 6, Loss: 0.9570\n",
            "Epoch 7, Loss: 0.8682\n",
            "Epoch 8, Loss: 0.8227\n",
            "Epoch 9, Loss: 0.7773\n",
            "Epoch 10, Loss: 0.7693\n",
            "Results for LR: 0.01, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.6491\n",
            "Precision: 0.6710\n",
            "Recall: 0.6476\n",
            "F1 Score: 0.6423\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.5311\n",
            "Epoch 2, Loss: 1.6897\n",
            "Epoch 3, Loss: 1.1488\n",
            "Epoch 4, Loss: 0.8968\n",
            "Epoch 5, Loss: 0.7294\n",
            "Epoch 6, Loss: 0.6589\n",
            "Epoch 7, Loss: 0.5374\n",
            "Epoch 8, Loss: 0.4715\n",
            "Epoch 9, Loss: 0.4103\n",
            "Epoch 10, Loss: 0.3299\n",
            "Results for LR: 0.01, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.6486\n",
            "Precision: 0.6731\n",
            "Recall: 0.6490\n",
            "F1 Score: 0.6462\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.9149\n",
            "Epoch 2, Loss: 3.8472\n",
            "Epoch 3, Loss: 3.8465\n",
            "Epoch 4, Loss: 3.8472\n",
            "Epoch 5, Loss: 3.8470\n",
            "Epoch 6, Loss: 3.8464\n",
            "Epoch 7, Loss: 3.8470\n",
            "Epoch 8, Loss: 3.8470\n",
            "Epoch 9, Loss: 3.8464\n",
            "Epoch 10, Loss: 3.8468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LR: 0.01, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.0206\n",
            "Precision: 0.0004\n",
            "Recall: 0.0213\n",
            "F1 Score: 0.0009\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.0163\n",
            "Epoch 2, Loss: 3.8471\n",
            "Epoch 3, Loss: 3.8466\n",
            "Epoch 4, Loss: 3.8473\n",
            "Epoch 5, Loss: 3.8462\n",
            "Epoch 6, Loss: 3.8466\n",
            "Epoch 7, Loss: 3.8472\n",
            "Epoch 8, Loss: 3.8466\n",
            "Epoch 9, Loss: 3.8468\n",
            "Epoch 10, Loss: 3.8464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LR: 0.01, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.0217\n",
            "Precision: 0.0005\n",
            "Recall: 0.0213\n",
            "F1 Score: 0.0009\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.2449\n",
            "Epoch 2, Loss: 1.5424\n",
            "Epoch 3, Loss: 1.1185\n",
            "Epoch 4, Loss: 0.8762\n",
            "Epoch 5, Loss: 0.7749\n",
            "Epoch 6, Loss: 0.6828\n",
            "Epoch 7, Loss: 0.5881\n",
            "Epoch 8, Loss: 0.5784\n",
            "Epoch 9, Loss: 0.5272\n",
            "Epoch 10, Loss: 0.4409\n",
            "Results for LR: 0.01, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.6758\n",
            "Precision: 0.6837\n",
            "Recall: 0.6758\n",
            "F1 Score: 0.6725\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.6377\n",
            "Epoch 2, Loss: 1.3303\n",
            "Epoch 3, Loss: 0.8509\n",
            "Epoch 4, Loss: 0.6316\n",
            "Epoch 5, Loss: 0.5341\n",
            "Epoch 6, Loss: 0.4460\n",
            "Epoch 7, Loss: 0.3675\n",
            "Epoch 8, Loss: 0.2806\n",
            "Epoch 9, Loss: 0.2816\n",
            "Epoch 10, Loss: 0.3075\n",
            "Results for LR: 0.01, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.6713\n",
            "Precision: 0.7046\n",
            "Recall: 0.6714\n",
            "F1 Score: 0.6623\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.4434\n",
            "Epoch 2, Loss: 1.8484\n",
            "Epoch 3, Loss: 1.3645\n",
            "Epoch 4, Loss: 1.1457\n",
            "Epoch 5, Loss: 0.9867\n",
            "Epoch 6, Loss: 0.8795\n",
            "Epoch 7, Loss: 0.7655\n",
            "Epoch 8, Loss: 0.7281\n",
            "Epoch 9, Loss: 0.6648\n",
            "Epoch 10, Loss: 0.5967\n",
            "Results for LR: 0.01, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.6316\n",
            "Precision: 0.6488\n",
            "Recall: 0.6321\n",
            "F1 Score: 0.6229\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.01, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.0238\n",
            "Epoch 2, Loss: 2.9499\n",
            "Epoch 3, Loss: 1.8322\n",
            "Epoch 4, Loss: 1.4095\n",
            "Epoch 5, Loss: 1.1751\n",
            "Epoch 6, Loss: 0.9486\n",
            "Epoch 7, Loss: 0.8230\n",
            "Epoch 8, Loss: 0.7011\n",
            "Epoch 9, Loss: 0.6145\n",
            "Epoch 10, Loss: 0.5363\n",
            "Results for LR: 0.01, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.6221\n",
            "Precision: 0.6378\n",
            "Recall: 0.6238\n",
            "F1 Score: 0.6177\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.5466\n",
            "Epoch 2, Loss: 1.1121\n",
            "Epoch 3, Loss: 0.7446\n",
            "Epoch 4, Loss: 0.5443\n",
            "Epoch 5, Loss: 0.4381\n",
            "Epoch 6, Loss: 0.3406\n",
            "Epoch 7, Loss: 0.2697\n",
            "Epoch 8, Loss: 0.2215\n",
            "Epoch 9, Loss: 0.2063\n",
            "Epoch 10, Loss: 0.1594\n",
            "Results for LR: 0.001, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.7632\n",
            "Precision: 0.7698\n",
            "Recall: 0.7636\n",
            "F1 Score: 0.7594\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.6086\n",
            "Epoch 2, Loss: 1.1309\n",
            "Epoch 3, Loss: 0.7771\n",
            "Epoch 4, Loss: 0.5965\n",
            "Epoch 5, Loss: 0.4562\n",
            "Epoch 6, Loss: 0.3572\n",
            "Epoch 7, Loss: 0.2944\n",
            "Epoch 8, Loss: 0.2410\n",
            "Epoch 9, Loss: 0.2080\n",
            "Epoch 10, Loss: 0.1697\n",
            "Results for LR: 0.001, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.7743\n",
            "Precision: 0.7840\n",
            "Recall: 0.7724\n",
            "F1 Score: 0.7662\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.7300\n",
            "Epoch 2, Loss: 1.2432\n",
            "Epoch 3, Loss: 0.8628\n",
            "Epoch 4, Loss: 0.6457\n",
            "Epoch 5, Loss: 0.4915\n",
            "Epoch 6, Loss: 0.4070\n",
            "Epoch 7, Loss: 0.3039\n",
            "Epoch 8, Loss: 0.2505\n",
            "Epoch 9, Loss: 0.2164\n",
            "Epoch 10, Loss: 0.1747\n",
            "Results for LR: 0.001, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.7565\n",
            "Precision: 0.7653\n",
            "Recall: 0.7563\n",
            "F1 Score: 0.7524\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.6720\n",
            "Epoch 2, Loss: 1.1597\n",
            "Epoch 3, Loss: 0.7728\n",
            "Epoch 4, Loss: 0.5892\n",
            "Epoch 5, Loss: 0.4604\n",
            "Epoch 6, Loss: 0.3659\n",
            "Epoch 7, Loss: 0.2873\n",
            "Epoch 8, Loss: 0.2196\n",
            "Epoch 9, Loss: 0.2097\n",
            "Epoch 10, Loss: 0.1629\n",
            "Results for LR: 0.001, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.7597\n",
            "Precision: 0.7812\n",
            "Recall: 0.7585\n",
            "F1 Score: 0.7601\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.0381\n",
            "Epoch 2, Loss: 1.4610\n",
            "Epoch 3, Loss: 0.9684\n",
            "Epoch 4, Loss: 0.7249\n",
            "Epoch 5, Loss: 0.5644\n",
            "Epoch 6, Loss: 0.4636\n",
            "Epoch 7, Loss: 0.3765\n",
            "Epoch 8, Loss: 0.3083\n",
            "Epoch 9, Loss: 0.2656\n",
            "Epoch 10, Loss: 0.2161\n",
            "Results for LR: 0.001, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.7735\n",
            "Precision: 0.7851\n",
            "Recall: 0.7739\n",
            "F1 Score: 0.7719\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8392\n",
            "Epoch 2, Loss: 1.2329\n",
            "Epoch 3, Loss: 0.8307\n",
            "Epoch 4, Loss: 0.6379\n",
            "Epoch 5, Loss: 0.4875\n",
            "Epoch 6, Loss: 0.4016\n",
            "Epoch 7, Loss: 0.3281\n",
            "Epoch 8, Loss: 0.2499\n",
            "Epoch 9, Loss: 0.2127\n",
            "Epoch 10, Loss: 0.2052\n",
            "Results for LR: 0.001, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.7716\n",
            "Precision: 0.7805\n",
            "Recall: 0.7710\n",
            "F1 Score: 0.7682\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.1669\n",
            "Epoch 2, Loss: 1.5263\n",
            "Epoch 3, Loss: 1.0186\n",
            "Epoch 4, Loss: 0.7869\n",
            "Epoch 5, Loss: 0.6160\n",
            "Epoch 6, Loss: 0.5200\n",
            "Epoch 7, Loss: 0.4106\n",
            "Epoch 8, Loss: 0.3239\n",
            "Epoch 9, Loss: 0.2878\n",
            "Epoch 10, Loss: 0.2406\n",
            "Results for LR: 0.001, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.7616\n",
            "Precision: 0.7748\n",
            "Recall: 0.7621\n",
            "F1 Score: 0.7562\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.001, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.1667\n",
            "Epoch 2, Loss: 1.5625\n",
            "Epoch 3, Loss: 1.0619\n",
            "Epoch 4, Loss: 0.8116\n",
            "Epoch 5, Loss: 0.6683\n",
            "Epoch 6, Loss: 0.5528\n",
            "Epoch 7, Loss: 0.4751\n",
            "Epoch 8, Loss: 0.3877\n",
            "Epoch 9, Loss: 0.3259\n",
            "Epoch 10, Loss: 0.2935\n",
            "Results for LR: 0.001, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.7587\n",
            "Precision: 0.7664\n",
            "Recall: 0.7601\n",
            "F1 Score: 0.7570\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2526\n",
            "Epoch 2, Loss: 0.9308\n",
            "Epoch 3, Loss: 0.6270\n",
            "Epoch 4, Loss: 0.4758\n",
            "Epoch 5, Loss: 0.3612\n",
            "Epoch 6, Loss: 0.3099\n",
            "Epoch 7, Loss: 0.3051\n",
            "Epoch 8, Loss: 0.2275\n",
            "Epoch 9, Loss: 0.2035\n",
            "Epoch 10, Loss: 0.1980\n",
            "Results for LR: 0.003, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.7507\n",
            "Precision: 0.7647\n",
            "Recall: 0.7532\n",
            "F1 Score: 0.7495\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.7348\n",
            "Epoch 2, Loss: 1.1922\n",
            "Epoch 3, Loss: 0.8676\n",
            "Epoch 4, Loss: 0.6931\n",
            "Epoch 5, Loss: 0.6067\n",
            "Epoch 6, Loss: 0.5014\n",
            "Epoch 7, Loss: 0.4404\n",
            "Epoch 8, Loss: 0.3744\n",
            "Epoch 9, Loss: 0.3382\n",
            "Epoch 10, Loss: 0.2934\n",
            "Results for LR: 0.003, Batch Size: 32, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.7296\n",
            "Precision: 0.7444\n",
            "Recall: 0.7310\n",
            "F1 Score: 0.7265\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.4288\n",
            "Epoch 2, Loss: 0.9700\n",
            "Epoch 3, Loss: 0.6514\n",
            "Epoch 4, Loss: 0.4884\n",
            "Epoch 5, Loss: 0.4083\n",
            "Epoch 6, Loss: 0.3289\n",
            "Epoch 7, Loss: 0.2458\n",
            "Epoch 8, Loss: 0.2275\n",
            "Epoch 9, Loss: 0.1927\n",
            "Epoch 10, Loss: 0.1945\n",
            "Results for LR: 0.003, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.7454\n",
            "Precision: 0.7618\n",
            "Recall: 0.7463\n",
            "F1 Score: 0.7461\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8341\n",
            "Epoch 2, Loss: 1.4628\n",
            "Epoch 3, Loss: 1.0825\n",
            "Epoch 4, Loss: 0.8814\n",
            "Epoch 5, Loss: 0.7450\n",
            "Epoch 6, Loss: 0.6570\n",
            "Epoch 7, Loss: 0.5873\n",
            "Epoch 8, Loss: 0.5337\n",
            "Epoch 9, Loss: 0.4703\n",
            "Epoch 10, Loss: 0.4391\n",
            "Results for LR: 0.003, Batch Size: 32, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.7044\n",
            "Precision: 0.7276\n",
            "Recall: 0.7061\n",
            "F1 Score: 0.7005\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.5581\n",
            "Epoch 2, Loss: 1.0750\n",
            "Epoch 3, Loss: 0.7257\n",
            "Epoch 4, Loss: 0.5257\n",
            "Epoch 5, Loss: 0.4132\n",
            "Epoch 6, Loss: 0.3409\n",
            "Epoch 7, Loss: 0.2716\n",
            "Epoch 8, Loss: 0.2193\n",
            "Epoch 9, Loss: 0.1843\n",
            "Epoch 10, Loss: 0.1565\n",
            "Results for LR: 0.003, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 3\n",
            "Accuracy: 0.7597\n",
            "Precision: 0.7692\n",
            "Recall: 0.7589\n",
            "F1 Score: 0.7552\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.5775\n",
            "Epoch 2, Loss: 1.0576\n",
            "Epoch 3, Loss: 0.6823\n",
            "Epoch 4, Loss: 0.5360\n",
            "Epoch 5, Loss: 0.3959\n",
            "Epoch 6, Loss: 0.2966\n",
            "Epoch 7, Loss: 0.2692\n",
            "Epoch 8, Loss: 0.2152\n",
            "Epoch 9, Loss: 0.1928\n",
            "Epoch 10, Loss: 0.1545\n",
            "Results for LR: 0.003, Batch Size: 64, Kernel Size1: 5, Kernel Size2: 5\n",
            "Accuracy: 0.7669\n",
            "Precision: 0.7786\n",
            "Recall: 0.7644\n",
            "F1 Score: 0.7599\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.1261\n",
            "Epoch 2, Loss: 1.4928\n",
            "Epoch 3, Loss: 0.9581\n",
            "Epoch 4, Loss: 0.7202\n",
            "Epoch 5, Loss: 0.5822\n",
            "Epoch 6, Loss: 0.4659\n",
            "Epoch 7, Loss: 0.4031\n",
            "Epoch 8, Loss: 0.3269\n",
            "Epoch 9, Loss: 0.2820\n",
            "Epoch 10, Loss: 0.2466\n",
            "Results for LR: 0.003, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 3\n",
            "Accuracy: 0.7423\n",
            "Precision: 0.7525\n",
            "Recall: 0.7451\n",
            "F1 Score: 0.7407\n",
            "--------------------------------------------------\n",
            "Training with Learning Rate: 0.003, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-73067a981159>:25: RuntimeWarning: invalid value encountered in cast\n",
            "  image = self.images[idx].astype(np.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8339\n",
            "Epoch 2, Loss: 1.3125\n",
            "Epoch 3, Loss: 0.8662\n",
            "Epoch 4, Loss: 0.6917\n",
            "Epoch 5, Loss: 0.5419\n",
            "Epoch 6, Loss: 0.4679\n",
            "Epoch 7, Loss: 0.3502\n",
            "Epoch 8, Loss: 0.3251\n",
            "Epoch 9, Loss: 0.2986\n",
            "Epoch 10, Loss: 0.2395\n",
            "Results for LR: 0.003, Batch Size: 64, Kernel Size1: 3, Kernel Size2: 5\n",
            "Accuracy: 0.7388\n",
            "Precision: 0.7496\n",
            "Recall: 0.7404\n",
            "F1 Score: 0.7337\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, mapping_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.mapping = {int(line.split()[0]): chr(int(line.split()[1])) for line in open(mapping_file).readlines()}\n",
        "        self.labels = self.data.iloc[:, 0].values  # First column is the label\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28)  # 28x28 images\n",
        "        self.transform = transform\n",
        "\n",
        "        # Ensure labels are zero-indexed by subtracting the minimum label value\n",
        "        self.min_label = min(self.labels)\n",
        "        self.labels = self.labels - self.min_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = np.uint8(image)  # Ensure the image is in uint8 format\n",
        "        if self.transform:\n",
        "            image = self.transform(Image.fromarray(image))\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (1 channel)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = CharacterDataset('/content/characters.csv', '/content/mapping.txt', transform=transform)\n",
        "test_dataset = CharacterDataset('/content/characters-test.csv', '/content/mapping.txt', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load a pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Adjust the output layer to match the number of classes\n",
        "num_classes = len(set(train_dataset.labels))\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" not in name and \"fc\" not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    model.to(device) # Move the model to the device\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in dataloader:\n",
        "            # Ensure labels are LongTensor and on the correct device\n",
        "            images = images.float().to(device)  # Move images to device and ensure float type\n",
        "            labels = labels.long().to(device)  # Move labels to device and ensure long type\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Training\n",
        "train_model(model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    report = classification_report(all_labels, all_preds, target_names=[str(c) for c in range(num_classes)])\n",
        "    # print(report)\n",
        "\n",
        "# Evaluation\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"pretrained_emnist_model.pth\")\n",
        "print(\"Model saved as pretrained_emnist_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxD6LJ-dIhqa",
        "outputId": "16e61d40-fd08-4e29-ac83-b9b0eff5f6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-4-7891a5dcb9e5>:29: RuntimeWarning: invalid value encountered in cast\n",
            "  image = np.uint8(image)  # Ensure the image is in uint8 format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.6412\n",
            "Epoch 2/10, Loss: 1.5127\n",
            "Epoch 3/10, Loss: 1.2321\n",
            "Epoch 4/10, Loss: 1.0431\n",
            "Epoch 5/10, Loss: 0.9236\n",
            "Epoch 6/10, Loss: 0.8109\n",
            "Epoch 7/10, Loss: 0.7180\n",
            "Epoch 8/10, Loss: 0.6651\n",
            "Epoch 9/10, Loss: 0.5648\n",
            "Epoch 10/10, Loss: 0.5183\n",
            "Model saved as pretrained_emnist_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet18 Pre-Trained Model"
      ],
      "metadata": {
        "id": "NoLgTt1pPQc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Define the dataset\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, csv_file, mapping_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.mapping = {int(line.split()[0]): chr(int(line.split()[1])) for line in open(mapping_file).readlines()}\n",
        "        self.labels = self.data.iloc[:, 0].values\n",
        "        self.images = self.data.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
        "        self.transform = transform\n",
        "        self.min_label = min(self.labels)\n",
        "        self.labels = self.labels - self.min_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = np.uint8(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(Image.fromarray(image))\n",
        "        return image, label\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = CharacterDataset('/content/characters.csv', '/content/mapping.txt', transform=transform)\n",
        "test_dataset = CharacterDataset('/content/characters-test.csv', '/content/mapping.txt', transform=transform)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "learning_rates = [0.01, 0.001, 0.003]\n",
        "batch_sizes = [32, 64]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"Training with Learning Rate: {lr}, Batch Size: {batch_size}\")\n",
        "\n",
        "        # Create data loaders with the current batch size\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Load and modify ResNet18\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        num_classes = len(set(train_dataset.labels))\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "        # Freeze layers except the last layers\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"layer4\" not in name and \"fc\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Define loss function and optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        # Move model to device\n",
        "        model.to(device)\n",
        "\n",
        "        # Training loop\n",
        "        def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "            model.train()\n",
        "            for epoch in range(epochs):\n",
        "                total_loss = 0\n",
        "                for images, labels in dataloader:\n",
        "                    images = images.float().to(device)\n",
        "                    labels = labels.long().to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    total_loss += loss.item()\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "        train_model(model, train_loader, criterion, optimizer)\n",
        "\n",
        "        # Evaluation loop\n",
        "        def evaluate_model(model, dataloader):\n",
        "            model.eval()\n",
        "            all_labels = []\n",
        "            all_preds = []\n",
        "            with torch.no_grad():\n",
        "                for images, labels in dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "            return all_labels, all_preds\n",
        "\n",
        "        all_labels, all_preds = evaluate_model(model, test_loader)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "        print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WplnRchMVQj",
        "outputId": "ddefd6d4-f8c1-4645-99cc-70ad689398b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Learning Rate: 0.01, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4625\n",
            "Epoch 2/10, Loss: 1.0609\n",
            "Epoch 3/10, Loss: 0.9688\n",
            "Epoch 4/10, Loss: 0.9078\n",
            "Epoch 5/10, Loss: 0.8657\n",
            "Epoch 6/10, Loss: 0.8263\n",
            "Epoch 7/10, Loss: 0.8028\n",
            "Epoch 8/10, Loss: 0.7758\n",
            "Epoch 9/10, Loss: 0.7548\n",
            "Epoch 10/10, Loss: 0.7321\n",
            "Accuracy: 0.7349, Precision: 0.7404, Recall: 0.7349, F1-Score: 0.7319\n",
            "==================================================\n",
            "Training with Learning Rate: 0.01, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3638\n",
            "Epoch 2/10, Loss: 0.9166\n",
            "Epoch 3/10, Loss: 0.8221\n",
            "Epoch 4/10, Loss: 0.7582\n",
            "Epoch 5/10, Loss: 0.7096\n",
            "Epoch 6/10, Loss: 0.6676\n",
            "Epoch 7/10, Loss: 0.6363\n",
            "Epoch 8/10, Loss: 0.5989\n",
            "Epoch 9/10, Loss: 0.5710\n",
            "Epoch 10/10, Loss: 0.5438\n",
            "Accuracy: 0.7430, Precision: 0.7484, Recall: 0.7430, F1-Score: 0.7413\n",
            "==================================================\n",
            "Training with Learning Rate: 0.001, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3465\n",
            "Epoch 2/10, Loss: 0.9494\n",
            "Epoch 3/10, Loss: 0.8277\n",
            "Epoch 4/10, Loss: 0.7434\n",
            "Epoch 5/10, Loss: 0.6772\n",
            "Epoch 6/10, Loss: 0.6243\n",
            "Epoch 7/10, Loss: 0.5829\n",
            "Epoch 8/10, Loss: 0.5429\n",
            "Epoch 9/10, Loss: 0.5120\n",
            "Epoch 10/10, Loss: 0.4826\n",
            "Accuracy: 0.7716, Precision: 0.7736, Recall: 0.7716, F1-Score: 0.7706\n",
            "==================================================\n",
            "Training with Learning Rate: 0.001, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3078\n",
            "Epoch 2/10, Loss: 0.9044\n",
            "Epoch 3/10, Loss: 0.7812\n",
            "Epoch 4/10, Loss: 0.6894\n",
            "Epoch 5/10, Loss: 0.6246\n",
            "Epoch 6/10, Loss: 0.5616\n",
            "Epoch 7/10, Loss: 0.5129\n",
            "Epoch 8/10, Loss: 0.4703\n",
            "Epoch 9/10, Loss: 0.4319\n",
            "Epoch 10/10, Loss: 0.3963\n",
            "Accuracy: 0.7486, Precision: 0.7532, Recall: 0.7486, F1-Score: 0.7463\n",
            "==================================================\n",
            "Training with Learning Rate: 0.003, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3916\n",
            "Epoch 2/10, Loss: 0.9356\n",
            "Epoch 3/10, Loss: 0.8229\n",
            "Epoch 4/10, Loss: 0.7448\n",
            "Epoch 5/10, Loss: 0.6885\n",
            "Epoch 6/10, Loss: 0.6468\n",
            "Epoch 7/10, Loss: 0.6004\n",
            "Epoch 8/10, Loss: 0.5752\n",
            "Epoch 9/10, Loss: 0.5474\n",
            "Epoch 10/10, Loss: 0.5230\n",
            "Accuracy: 0.7610, Precision: 0.7635, Recall: 0.7610, F1-Score: 0.7586\n",
            "==================================================\n",
            "Training with Learning Rate: 0.003, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3235\n",
            "Epoch 2/10, Loss: 0.8932\n",
            "Epoch 3/10, Loss: 0.7697\n",
            "Epoch 4/10, Loss: 0.6832\n",
            "Epoch 5/10, Loss: 0.6110\n",
            "Epoch 6/10, Loss: 0.5515\n",
            "Epoch 7/10, Loss: 0.5031\n",
            "Epoch 8/10, Loss: 0.4579\n",
            "Epoch 9/10, Loss: 0.4214\n",
            "Epoch 10/10, Loss: 0.3856\n",
            "Accuracy: 0.7534, Precision: 0.7554, Recall: 0.7534, F1-Score: 0.7519\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Subjectivity Detection"
      ],
      "metadata": {
        "id": "qHyuKfA5pqaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "Vm6ELmrSpymD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq2y6Gnvc5CN",
        "outputId": "333dce54-1a6a-452f-85ca-bafb218a2420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load your custom dataset\n",
        "train_file = \"/content/train_en.tsv\"\n",
        "test_file = \"/content/test_en_gold.tsv\"\n",
        "\n",
        "def load_data(file_path):\n",
        "    dataset = load_dataset('csv', data_files=file_path, delimiter=\"\\t\", split='train')\n",
        "    return dataset\n",
        "\n",
        "train_data = load_data(train_file)\n",
        "test_data = load_data(test_file)\n",
        "\n",
        "# Map string labels to numerical labels\n",
        "def label_map(label):\n",
        "    return {'SUBJ': 0, 'OBJ': 1}.get(label, -1)\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_data(examples):\n",
        "    examples['label'] = [label_map(label) for label in examples['label']]\n",
        "    return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_data = train_data.map(preprocess_data, batched=True)\n",
        "test_data = test_data.map(preprocess_data, batched=True)\n",
        "\n",
        "train_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "learning_rates = [0.01, 0.001, 2e-5]\n",
        "batch_sizes = [32, 64]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Variables to track the best model\n",
        "best_model = None\n",
        "best_metrics = {\"accuracy\": 0}\n",
        "best_hyperparams = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"Training with Learning Rate: {lr}, Batch Size: {batch_size}\")\n",
        "\n",
        "        # Create data loaders\n",
        "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "        # Load and configure model\n",
        "        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "        model.to(device)\n",
        "\n",
        "        # Define optimizer\n",
        "        optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "        # Training function\n",
        "        def train(model, train_dataloader, optimizer, device, epochs=10):  # Reduced epochs for hyperparameter testing\n",
        "            model.train()\n",
        "            for epoch in range(epochs):\n",
        "                total_loss = 0\n",
        "                for batch in train_dataloader:\n",
        "                    optimizer.zero_grad()\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                    total_loss += loss.item()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "        # Evaluation function\n",
        "        def evaluate(model, test_dataloader, device):\n",
        "            model.eval()\n",
        "            predictions, true_labels = [], []\n",
        "            with torch.no_grad():\n",
        "                for batch in test_dataloader:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    preds = torch.argmax(logits, dim=-1)\n",
        "                    predictions.extend(preds.cpu().numpy())\n",
        "                    true_labels.extend(labels.cpu().numpy())\n",
        "            accuracy = accuracy_score(true_labels, predictions)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
        "            return accuracy, precision, recall, f1\n",
        "\n",
        "        # Train and evaluate the model\n",
        "        train(model, train_dataloader, optimizer, device)\n",
        "        accuracy, precision, recall, f1 = evaluate(model, test_dataloader, device)\n",
        "        print(f\"Metrics: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "        # Update best model if current metrics are better\n",
        "        if accuracy > best_metrics[\"accuracy\"]:\n",
        "            best_metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "            best_hyperparams = {\"learning_rate\": lr, \"batch_size\": batch_size}\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "# Print the best model's metrics and hyperparameters\n",
        "print(\"\\nBest Model:\")\n",
        "print(f\"Learning Rate: {best_hyperparams['learning_rate']}, Batch Size: {best_hyperparams['batch_size']}\")\n",
        "print(f\"Metrics: Accuracy={best_metrics['accuracy']:.4f}, Precision={best_metrics['precision']:.4f}, Recall={best_metrics['recall']:.4f}, F1={best_metrics['f1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6e2r8wiccTs",
        "outputId": "494f7fa9-9057-4014-b907-bc2ad7db7922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Learning Rate: 0.01, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4501\n",
            "Epoch 2/10, Loss: 0.8692\n",
            "Epoch 3/10, Loss: 0.7946\n",
            "Epoch 4/10, Loss: 0.7707\n",
            "Epoch 5/10, Loss: 0.7805\n",
            "Epoch 6/10, Loss: 0.7820\n",
            "Epoch 7/10, Loss: 0.8717\n",
            "Epoch 8/10, Loss: 0.8379\n",
            "Epoch 9/10, Loss: 0.8850\n",
            "Epoch 10/10, Loss: 0.6988\n",
            "Metrics: Accuracy=0.4774, Precision=0.4774, Recall=1.0000, F1=0.6462\n",
            "Training with Learning Rate: 0.01, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 3.2582\n",
            "Epoch 2/10, Loss: 0.9983\n",
            "Epoch 3/10, Loss: 0.7802\n",
            "Epoch 4/10, Loss: 0.7597\n",
            "Epoch 5/10, Loss: 0.8025\n",
            "Epoch 6/10, Loss: 0.6923\n",
            "Epoch 7/10, Loss: 0.7317\n",
            "Epoch 8/10, Loss: 0.7799\n",
            "Epoch 9/10, Loss: 0.7549\n",
            "Epoch 10/10, Loss: 0.8052\n",
            "Metrics: Accuracy=0.4774, Precision=0.4774, Recall=1.0000, F1=0.6462\n",
            "Training with Learning Rate: 0.001, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7166\n",
            "Epoch 2/10, Loss: 0.7085\n",
            "Epoch 3/10, Loss: 0.6741\n",
            "Epoch 4/10, Loss: 0.6591\n",
            "Epoch 5/10, Loss: 0.6599\n",
            "Epoch 6/10, Loss: 0.6555\n",
            "Epoch 7/10, Loss: 0.6596\n",
            "Epoch 8/10, Loss: 0.6585\n",
            "Epoch 9/10, Loss: 0.6579\n",
            "Epoch 10/10, Loss: 0.6630\n",
            "Metrics: Accuracy=0.4774, Precision=0.4774, Recall=1.0000, F1=0.6462\n",
            "Training with Learning Rate: 0.001, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.9251\n",
            "Epoch 2/10, Loss: 0.7999\n",
            "Epoch 3/10, Loss: 0.6681\n",
            "Epoch 4/10, Loss: 0.6815\n",
            "Epoch 5/10, Loss: 0.6704\n",
            "Epoch 6/10, Loss: 0.6581\n",
            "Epoch 7/10, Loss: 0.6669\n",
            "Epoch 8/10, Loss: 0.6731\n",
            "Epoch 9/10, Loss: 0.6619\n",
            "Epoch 10/10, Loss: 0.6667\n",
            "Metrics: Accuracy=0.4774, Precision=0.4774, Recall=1.0000, F1=0.6462\n",
            "Training with Learning Rate: 2e-05, Batch Size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6244\n",
            "Epoch 2/10, Loss: 0.4885\n",
            "Epoch 3/10, Loss: 0.3361\n",
            "Epoch 4/10, Loss: 0.1777\n",
            "Epoch 5/10, Loss: 0.0669\n",
            "Epoch 6/10, Loss: 0.0318\n",
            "Epoch 7/10, Loss: 0.0171\n",
            "Epoch 8/10, Loss: 0.0169\n",
            "Epoch 9/10, Loss: 0.0143\n",
            "Epoch 10/10, Loss: 0.0170\n",
            "Metrics: Accuracy=0.7284, Precision=0.6812, Recall=0.8103, F1=0.7402\n",
            "Training with Learning Rate: 2e-05, Batch Size: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6056\n",
            "Epoch 2/10, Loss: 0.4542\n",
            "Epoch 3/10, Loss: 0.3456\n",
            "Epoch 4/10, Loss: 0.2555\n",
            "Epoch 5/10, Loss: 0.1852\n",
            "Epoch 6/10, Loss: 0.1364\n",
            "Epoch 7/10, Loss: 0.1024\n",
            "Epoch 8/10, Loss: 0.0740\n",
            "Epoch 9/10, Loss: 0.0657\n",
            "Epoch 10/10, Loss: 0.0516\n",
            "Metrics: Accuracy=0.7037, Precision=0.6410, Recall=0.8621, F1=0.7353\n",
            "\n",
            "Best Model:\n",
            "Learning Rate: 2e-05, Batch Size: 32\n",
            "Metrics: Accuracy=0.7284, Precision=0.6812, Recall=0.8103, F1=0.7402\n"
          ]
        }
      ]
    }
  ]
}